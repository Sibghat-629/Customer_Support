{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dc49826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Set your Groq API key\n",
    "os.environ[\"GROQ_API_KEY\"] = \""  # <-- REPLACE WITH YOUR KEY\n",
    "\n",
    "# Initialize Groq LLM (e.g., mixtral, llama3-70b, gemma-7b)\n",
    "llm = ChatGroq(\n",
    "    model=\"llama3-70b-8192\",  # or \"llama3-70b-8192\", \"gemma-7b-it\"\n",
    "    temperature=0.1,\n",
    "    request_timeout=60\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff623363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 30 pages and split into 97 chunks.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load your PDF\n",
    "loader = PyPDFLoader(\"mypdf_customer.pdf\")  # <-- CHANGE THIS\n",
    "pages = loader.load()\n",
    "\n",
    "# Split text into chunks\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(pages)\n",
    "\n",
    "print(f\"Loaded {len(pages)} pages and split into {len(chunks)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "142cec54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sibghatullah\\AppData\\Local\\Temp\\ipykernel_1016\\4199777356.py:14: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ea60f3c8057545beae2d184f03418d68',\n",
       " 'f1cff6b4373a46b782ccd904b476b3d6',\n",
       " '25a97e1adfc741e482d3481664e71cb7',\n",
       " '8c1f301474a84b1182b780fd5f7462ad',\n",
       " 'a3bb6ab3fd0f4ae991cf5d10aa326296',\n",
       " '56e1df6c0a20425486e33189096afc87',\n",
       " '75673f35b12b415b90ec1349131a1c68',\n",
       " 'dd3779febeb54045889d8671c02762a4',\n",
       " '3c15cfdf5c844cd083a0936365865d02',\n",
       " 'dc668afd45dc47e4ad62b8bc482de5cb',\n",
       " '47bf4095608d4548b81995324b0ee93e',\n",
       " 'fe3156fdaefa4016b2d4dbdff8bdac0b',\n",
       " 'fbc4b2b8e1b047ac829124162f1bd747',\n",
       " 'fa7c989d35b348be951df1aa8e172da7',\n",
       " '3bd80afd7ff24d33b8ab95bba4497ac8',\n",
       " 'e29765665f934be5aed3484a959307c9',\n",
       " '07f499fb65ae40109c3a41a9b0923946',\n",
       " 'db3ec067079f46b688def6c0be66e266',\n",
       " '2daf185c3eb54986b6c5b7bb65bd269f',\n",
       " '7db4296576fa48e2bf3f349e36578bdc',\n",
       " 'd43cd426c74243b492e6b645454ea172',\n",
       " 'e12c5ad4beed415a946f6b765bc3bcd8',\n",
       " 'b7b8361a7ba14d539525121dc156e5f7',\n",
       " '2624a646366941a7a4add05c03fa9484',\n",
       " 'dd6a576a27e748dc95af6a777b0e3de3',\n",
       " '2a9e8ae727544e828a08ef765226981f',\n",
       " '0235e468c58e49abb22913f86ba1c514',\n",
       " '65238fe5eaba4a9cb10b4fdd52f0daaf',\n",
       " 'aa1376ed67d4486f925ab11ec220975e',\n",
       " '6d138642989a447ab66bbeb658b87f17',\n",
       " 'd8464b43313d4c3388c0e1350aedf8a5',\n",
       " '3f3a247ba9bb4a119782ec620dbca76d',\n",
       " '0cfc99837ca046a8b9a6ca61621fdc03',\n",
       " '760d8d9c1b5040d0b030157ad6986815',\n",
       " '92ac8202f3574a089d2b1eb3c7395055',\n",
       " '1d217a8bfbea46488edb7cc66e945bd1',\n",
       " 'a22f433b368040c59736b33eea617b0e',\n",
       " '6b150a622fe243a88538acef91c5c19d',\n",
       " '2a70a399e2e04b4aa994467a2f4ac7fb',\n",
       " '940e803660c34c7da83294b3a6f3aa73',\n",
       " '9ce287f0b3e84a39bca8917014cbfe1b',\n",
       " 'c1f964f5cfb44f0fb2626191f129bda4',\n",
       " '7e0ba9c02f61421daf76628810753f48',\n",
       " '3320fa01fe8941078befa1a4be9d25da',\n",
       " '9bb5927c9c684e6e94f031e5bd09aaf7',\n",
       " '7c635bcfad9f4350b5adc2bcdbc27b06',\n",
       " 'd93fa91893c748e6b7cf37e9eaba2878',\n",
       " '1a8c0694b3a74ace9f89ed6d4040e45a',\n",
       " '5ff468b12ab3496db4ef941e568b086d',\n",
       " '1dbad5c5a6fb4eac8feae8e169af350f',\n",
       " '5bc7fed001284058bc5e1231967bff96',\n",
       " '261cf460918e45dc9cdb255e56ddd808',\n",
       " '654b58ed8df04b57b7aa55d57f1fb0ab',\n",
       " 'f7bc4dbe46a944e7bfe73afd25091df2',\n",
       " 'f1925bd209c047a0ad96e8fd05cac3bf',\n",
       " '27ed7ff5392247fa816bea5051b361c7',\n",
       " '19158191f7744c4aa6e8cc0263ae1de7',\n",
       " '97c0f9aa23f14ddf8e3cff3d141e962f',\n",
       " 'f06bfed3a1e9499083ace524edf6e14e',\n",
       " '1ba957fb92dc4bdd9c0d87c87c1c4e9f',\n",
       " '04f66d37bd614ad186ef4436be4cb88e',\n",
       " '3c090de01eb14080b2b51c1ac33821d3',\n",
       " '9aed4696f05b42c59342023d04c45e31',\n",
       " '078fd95c65014b84ac11c12fbd605784',\n",
       " '98f36a9ebee54e888406fa6f14a025a5',\n",
       " 'ce4862e29df24bed9d6bf031048bb413',\n",
       " '002d1b9578ba4967a01ad476c75b473a',\n",
       " '18bd87ce46cd461bad7cec4eb6be67ff',\n",
       " 'bc4ad0abc0474c16a66e2ff73b3f2e05',\n",
       " '11ad89e4a263403fbd984af7e722e3e9',\n",
       " '173a083dfd994ee9a0991bd8dbc28c52',\n",
       " '8190dcf9033c4b62ad89c683c8ca0b28',\n",
       " 'ea3cd50acc5a46c1bd7aa6ba8647f8fa',\n",
       " 'd9d7c8587c0d481b8690fde9adf790fd',\n",
       " 'fbd31786b7574142823c8dfdfdcd81fa',\n",
       " 'bea82489643948bba1967ce13c7d6307',\n",
       " 'bec3e1af528346fdb1f4a9fb9d792a92',\n",
       " 'd0ecfa5dff574bb3b44d330a6380f6fc',\n",
       " 'd45c775b06ac453a80cae72a49a61996',\n",
       " '15c6f0b846eb4abd9095ec2837fa9087',\n",
       " '4638d9c611a44f77b4965ee31898761a',\n",
       " '2561bb2264f04669a244b7f28455319b',\n",
       " '064584bfb98a4dff80d259c5f674b73a',\n",
       " '188cce89bef44071b5ff84a41eb2005d',\n",
       " '677df6679d7b4e3d8334e5fdfb93834a',\n",
       " 'c8aabe988016488abce9887e380b830f',\n",
       " '415064a5b3f44540a0c53fc8fa46513a',\n",
       " 'f047c84638c3445996aa6f0e45d5fbc6',\n",
       " '5dce271b4b5a4c18b6f11037e20acea6',\n",
       " '80b18bbc90704d9f925ea76aac435e15',\n",
       " 'c65d7a5c15f440e3b7322e458b5f6c30',\n",
       " '0b47583403614c8188d39e4cce87f79f',\n",
       " '59e84a8b474c45ee9cca1b297eb4821c',\n",
       " '60dfc25934694086b54637981e7cc03a',\n",
       " '5318459ddf0b4cb6a7a066ff87b7454c',\n",
       " '808fd627487c44148e3fca9b331f3d2c',\n",
       " 'e8c23866e39d49708bb337ebd11eb244']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "\n",
    "# Embedding model\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Qdrant client (localhost)\n",
    "client = QdrantClient(host=\"localhost\", port=6333)\n",
    "\n",
    "# Recreate collection\n",
    "collection_name = \"customer_support_docs\"\n",
    "client.recreate_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=384, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "# Upload to Qdrant\n",
    "qdrant = Qdrant(\n",
    "    client=client,\n",
    "    collection_name=collection_name,\n",
    "    embeddings=embedding,\n",
    ")\n",
    "\n",
    "qdrant.add_documents(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8fec0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "# Graph input/output state\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    answer: str\n",
    "    docs: list\n",
    "\n",
    "# Create retriever from Qdrant\n",
    "retriever = qdrant.as_retriever()\n",
    "\n",
    "# Format documents\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Define the RAG node function\n",
    "def rag_node(state: GraphState):\n",
    "    question = state[\"question\"]\n",
    "    docs = retriever.get_relevant_documents(question)\n",
    "    context = format_docs(docs)\n",
    "    prompt = f\"Use the following context to answer the question:\\n\\n{context}\\n\\nQuestion: {question}\"\n",
    "    response = llm.invoke(prompt)\n",
    "    \n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"answer\": response.content,\n",
    "        \"docs\": docs\n",
    "    }\n",
    "\n",
    "# Build LangGraph\n",
    "graph = StateGraph(GraphState)\n",
    "graph.add_node(\"rag_node\", RunnableLambda(rag_node))\n",
    "graph.set_entry_point(\"rag_node\")\n",
    "graph.set_finish_point(\"rag_node\")\n",
    "app = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7f4b01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Based on the context, it appears that the SaaS company has a support structure that includes handling refunds as part of their customer support process. However, the exact return policy is not explicitly stated in the provided text.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = app.invoke({\"question\": \"What is your return policy?\"})\n",
    "    print(\"Answer:\", response[\"answer\"])\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"API Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7de2035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Transformers! One of the most powerful and widely used architectures in AI, particularly in natural language processing (NLP). I\\'d be happy to explain how they work.\\n\\n**What is a Transformer?**\\n\\nA transformer is a type of neural network architecture introduced in 2017 by Vaswani et al. in the paper \"Attention is All You Need.\" It\\'s primarily designed for sequence-to-sequence tasks, such as machine translation, text summarization, and language modeling.\\n\\n**Key Components:**\\n\\n1. **Self-Attention Mechanism**: This is the core innovation of transformers. It allows the model to attend to different parts of the input sequence simultaneously and weigh their importance. This is different from traditional recurrent neural networks (RNNs), which process sequences sequentially and have recurrence connections.\\n2. **Encoder-Decoder Structure**: The transformer model consists of an encoder and a decoder. The encoder takes in a sequence of tokens (e.g., words or characters) and outputs a continuous representation of the input sequence. The decoder generates the output sequence, one token at a time, based on the encoder\\'s output.\\n3. **Multi-Head Attention**: This is an extension of the self-attention mechanism. It allows the model to jointly attend to information from different representation subspaces at different positions.\\n\\n**How Transformers Work:**\\n\\n**Encoder:**\\n\\n1. **Token Embeddings**: The input sequence is first converted into a sequence of token embeddings, which are vector representations of each token.\\n2. **Positional Encoding**: The token embeddings are then added with positional encoding vectors, which capture the token\\'s position in the sequence.\\n3. **Self-Attention**: The encoder applies self-attention to the input sequence, computing the attention weights and output values for each token.\\n4. **Feed-Forward Network (FFN)**: The output of the self-attention mechanism is fed into a fully connected feed-forward network (FFN) to generate the final encoder output.\\n\\n**Decoder:**\\n\\n1. **Decoder Input**: The decoder takes the encoder output and generates the output sequence, one token at a time.\\n2. **Self-Attention**: The decoder applies self-attention to the output sequence generated so far, computing the attention weights and output values for each token.\\n3. **Encoder-Decoder Attention**: The decoder also attends to the encoder output, computing the attention weights and output values for each token.\\n4. **FFN**: The output of the self-attention and encoder-decoder attention mechanisms is fed into an FFN to generate the final output token.\\n\\n**Training:**\\n\\nThe transformer model is trained using a masked language modeling objective, where some input tokens are randomly replaced with a [MASK] token. The model predicts the original token, and the loss is calculated based on the difference between the predicted token and the original token.\\n\\n**Advantages:**\\n\\n1. **Parallelization**: Transformers can be parallelized more easily than RNNs, making them much faster to train and evaluate.\\n2. **Scalability**: Transformers can handle longer input sequences and larger models than RNNs.\\n3. **Performance**: Transformers have achieved state-of-the-art results in many NLP tasks, including machine translation, text classification, and language modeling.\\n\\nIn summary, transformers are a powerful architecture that have revolutionized the field of NLP. They\\'re particularly well-suited for sequence-to-sequence tasks and have achieved state-of-the-art results in many applications.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 697, 'prompt_tokens': 18, 'total_tokens': 715, 'completion_time': 2.565508694, 'prompt_time': 0.000255306, 'queue_time': 0.202070326, 'total_time': 2.565764}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_bf16903a67', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--948a8cf1-f431-4e4d-9a1d-0d867d3d7db6-0' usage_metadata={'input_tokens': 18, 'output_tokens': 697, 'total_tokens': 715}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# ✅ Set your Groq API key (keep this secure!)\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "\n",
    "# ✅ Initialize the Groq LLM\n",
    "llm = ChatGroq(\n",
    "    model=\"llama3-70b-8192\",  # Options: \"llama3-70b-8192\", \"gemma-7b-it\"\n",
    "    temperature=0.1,\n",
    "    request_timeout=60\n",
    ")\n",
    "\n",
    "# ✅ Example call\n",
    "response = llm.invoke(\"Explain how transformers work in AI.\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acc5130",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
